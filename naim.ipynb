{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d7a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Process a single frame for person detection (tracking not included)\n",
    "def process_frame(frame, model):\n",
    "    #frame actually a picture\n",
    "    results = model(frame)\n",
    "    detections = []\n",
    "\n",
    "    for box in results[0].boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        conf = float(box.conf)\n",
    "        cls = int(box.cls)\n",
    "\n",
    "        # class 0 = person in COCO\n",
    "        if cls == 0 and conf > 0.5:\n",
    "            detections.append([[x1, y1, x2 - x1, y2 - y1]])\n",
    "    \n",
    "    return detections\n",
    "\n",
    "\n",
    "# now, detections is a list of list like [[x, y, w, h]] which is the information of bounding boxes around the person detected in the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a779d9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 16 persons, 68.1ms\n",
      "Speed: 2.5ms preprocess, 68.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detections: [[175.90618896484375, 283.386474609375, 59.803466796875, 140.6126708984375], [22.92767333984375, 247.980224609375, 55.08995819091797, 135.06640625], [336.8275146484375, 20.076690673828125, 44.910888671875, 122.70515441894531], [269.208740234375, 222.44500732421875, 54.98626708984375, 134.27813720703125], [459.22979736328125, 239.7570343017578, 64.21868896484375, 123.30662536621094], [235.919921875, 138.51385498046875, 42.9990234375, 115.30282592773438], [302.77349853515625, 117.91400146484375, 46.9053955078125, 122.28732299804688], [95.42851257324219, 94.6858901977539, 44.63526916503906, 118.70928192138672], [131.28701782226562, 134.75360107421875, 45.83489990234375, 117.2784423828125], [189.84017944335938, 82.3543701171875, 48.1597900390625, 165.18399047851562], [71.75164794921875, 6.6855316162109375, 34.08937072753906, 105.83248901367188], [164.82196044921875, 160.82415771484375, 57.8238525390625, 148.7620849609375]]\n"
     ]
    }
   ],
   "source": [
    "### validation of the process_frame function ###\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Function to process frame (detect persons only)\n",
    "def process_frame(frame, model):\n",
    "    results = model(frame)\n",
    "    detections = []\n",
    "\n",
    "    for box in results[0].boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        conf = float(box.conf)\n",
    "        cls = int(box.cls)\n",
    "\n",
    "        # class 0 = person in COCO dataset\n",
    "        if cls == 0 and conf > 0.5:\n",
    "            detections.append([float(x1), float(y1), float(x2 - x1), float(y2 - y1)])  # [x, y, w, h]\n",
    "\n",
    "    return detections\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    image_path = \"20.jpg\"   \n",
    "    frame = cv2.imread(image_path)\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "\n",
    "    if frame is None:\n",
    "        print(\"Error: Image not found!\")\n",
    "        return\n",
    "\n",
    "    detections = process_frame(frame, model)\n",
    "    print(\"Detections:\", detections)\n",
    "\n",
    "    # Draw green rectangles for each detection\n",
    "    for (x, y, w, h) in detections:\n",
    "        x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Show the image\n",
    "    cv2.imshow(\"Person Detections\", frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f19f183",
   "metadata": {},
   "outputs": [],
   "source": [
    "### anomalies detection function ###\n",
    "\n",
    "def anomaly_detection(detections, frame):\n",
    "    \n",
    "\n",
    "    \n",
    "    return False  # No anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6302b726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6f6c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d126046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078990f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee240c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
